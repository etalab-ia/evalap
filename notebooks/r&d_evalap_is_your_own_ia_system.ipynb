{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33fde59-7aff-4f16-898d-95497d084548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from io import StringIO\n",
    "import concurrent.futures\n",
    "\n",
    "import dotenv\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from jinja2 import Template\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "\n",
    "EVALAP_API_URL = \"http://localhost:8000/v1\"\n",
    "#EVALAP_API_URL = \"https://evalap.etalab.gouv.fr/v1\"\n",
    "EVALAP_API_KEY = os.getenv(\"EVALAP_API_KEY\") \n",
    "ALBERT_API_URL = \"https://albert.api.etalab.gouv.fr/v1\"\n",
    "ALBERT_API_KEY = os.getenv(\"ALBERT_API_KEY\")\n",
    "OPENAI_URL = \"https://api.openai.com/v1\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "headers = {\"Authorization\": f\"Bearer {EVALAP_API_KEY}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64cb00e3-0309-4af1-b4e7-e92703de47c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>output_true</th>\n",
       "      <th>snippets</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consider the Marketing Affiliate Agreement bet...</td>\n",
       "      <td>This agreement shall begin upon the date of it...</td>\n",
       "      <td>[{'file_path': 'cuad/CybergyHoldingsInc_201405...</td>\n",
       "      <td>cuad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consider the Marketing Affiliate Agreement bet...</td>\n",
       "      <td>This agreement shall begin upon the date of it...</td>\n",
       "      <td>[{'file_path': 'cuad/CybergyHoldingsInc_201405...</td>\n",
       "      <td>cuad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consider the Marketing Affiliate Agreement bet...</td>\n",
       "      <td>This Agreement may be terminated by either par...</td>\n",
       "      <td>[{'file_path': 'cuad/CybergyHoldingsInc_201405...</td>\n",
       "      <td>cuad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consider the Marketing Affiliate Agreement bet...</td>\n",
       "      <td>This Agreement is accepted by Company in the S...</td>\n",
       "      <td>[{'file_path': 'cuad/CybergyHoldingsInc_201405...</td>\n",
       "      <td>cuad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consider the Marketing Affiliate Agreement bet...</td>\n",
       "      <td>MA may not assign, sell, lease or otherwise tr...</td>\n",
       "      <td>[{'file_path': 'cuad/CybergyHoldingsInc_201405...</td>\n",
       "      <td>cuad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6884</th>\n",
       "      <td>Consider VELCO's Non-Disclosure Agreement; Doe...</td>\n",
       "      <td>For purposes of this Agreement, “BCSI” shall m...</td>\n",
       "      <td>[{'file_path': 'contractnli/VELCO%20NDA%20rev0...</td>\n",
       "      <td>contractnli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885</th>\n",
       "      <td>Consider VELCO's Non-Disclosure Agreement; Doe...</td>\n",
       "      <td>The foregoing notwithstanding, the Recipient m...</td>\n",
       "      <td>[{'file_path': 'contractnli/VELCO%20NDA%20rev0...</td>\n",
       "      <td>contractnli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6886</th>\n",
       "      <td>Consider VELCO's Non-Disclosure Agreement; Doe...</td>\n",
       "      <td>5. In the event that the Recipient is required...</td>\n",
       "      <td>[{'file_path': 'contractnli/VELCO%20NDA%20rev0...</td>\n",
       "      <td>contractnli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6887</th>\n",
       "      <td>Consider VELCO's Non-Disclosure Agreement; Doe...</td>\n",
       "      <td>The foregoing notwithstanding, the Recipient m...</td>\n",
       "      <td>[{'file_path': 'contractnli/VELCO%20NDA%20rev0...</td>\n",
       "      <td>contractnli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>Consider VELCO's Non-Disclosure Agreement; Doe...</td>\n",
       "      <td>4. Recipient and each of its Representatives s...</td>\n",
       "      <td>[{'file_path': 'contractnli/VELCO%20NDA%20rev0...</td>\n",
       "      <td>contractnli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6889 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0     Consider the Marketing Affiliate Agreement bet...   \n",
       "1     Consider the Marketing Affiliate Agreement bet...   \n",
       "2     Consider the Marketing Affiliate Agreement bet...   \n",
       "3     Consider the Marketing Affiliate Agreement bet...   \n",
       "4     Consider the Marketing Affiliate Agreement bet...   \n",
       "...                                                 ...   \n",
       "6884  Consider VELCO's Non-Disclosure Agreement; Doe...   \n",
       "6885  Consider VELCO's Non-Disclosure Agreement; Doe...   \n",
       "6886  Consider VELCO's Non-Disclosure Agreement; Doe...   \n",
       "6887  Consider VELCO's Non-Disclosure Agreement; Doe...   \n",
       "6888  Consider VELCO's Non-Disclosure Agreement; Doe...   \n",
       "\n",
       "                                            output_true  \\\n",
       "0     This agreement shall begin upon the date of it...   \n",
       "1     This agreement shall begin upon the date of it...   \n",
       "2     This Agreement may be terminated by either par...   \n",
       "3     This Agreement is accepted by Company in the S...   \n",
       "4     MA may not assign, sell, lease or otherwise tr...   \n",
       "...                                                 ...   \n",
       "6884  For purposes of this Agreement, “BCSI” shall m...   \n",
       "6885  The foregoing notwithstanding, the Recipient m...   \n",
       "6886  5. In the event that the Recipient is required...   \n",
       "6887  The foregoing notwithstanding, the Recipient m...   \n",
       "6888  4. Recipient and each of its Representatives s...   \n",
       "\n",
       "                                               snippets dataset_name  \n",
       "0     [{'file_path': 'cuad/CybergyHoldingsInc_201405...         cuad  \n",
       "1     [{'file_path': 'cuad/CybergyHoldingsInc_201405...         cuad  \n",
       "2     [{'file_path': 'cuad/CybergyHoldingsInc_201405...         cuad  \n",
       "3     [{'file_path': 'cuad/CybergyHoldingsInc_201405...         cuad  \n",
       "4     [{'file_path': 'cuad/CybergyHoldingsInc_201405...         cuad  \n",
       "...                                                 ...          ...  \n",
       "6884  [{'file_path': 'contractnli/VELCO%20NDA%20rev0...  contractnli  \n",
       "6885  [{'file_path': 'contractnli/VELCO%20NDA%20rev0...  contractnli  \n",
       "6886  [{'file_path': 'contractnli/VELCO%20NDA%20rev0...  contractnli  \n",
       "6887  [{'file_path': 'contractnli/VELCO%20NDA%20rev0...  contractnli  \n",
       "6888  [{'file_path': 'contractnli/VELCO%20NDA%20rev0...  contractnli  \n",
       "\n",
       "[6889 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the dataset from Evalap\n",
    "# --\n",
    "dataset_name = \"LegalBenchRAG\"\n",
    "response = requests.get(\n",
    "    f\"{EVALAP_API_URL}/dataset?name={dataset_name}&with_df=true\",\n",
    "    headers={\"Authorization\": f\"Bearer {EVALAP_API_KEY}\"},\n",
    ")\n",
    "response.raise_for_status()\n",
    "dataset = response.json()\n",
    "dataset_df =  pd.read_json(StringIO(dataset[\"df\"]))\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "474ad967-2543-4f4d-91d0-24abe091d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 1000 random index to work with a subset of the dataset in order to do faster and cheaper evaluation\n",
    "# --\n",
    "N = len(dataset_df) # Size of the \n",
    "rng = np.random.default_rng(42)\n",
    "sample = rng.choice(np.arange(N), size=1000, replace=False)\n",
    "sample = sample.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0867c195-260b-4d93-9abc-2337c9ba7c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created expset: LegalBenchRAG Evaluation (111)\n"
     ]
    }
   ],
   "source": [
    "# Initial NORAG experiments\n",
    "# --\n",
    "\n",
    "expset_name = \"LegalBenchRAG Evaluation\"\n",
    "expset_readme = \"A extensive RAG evaluation on the LegalBecnhRAG dataset. See [complete me]\"\n",
    "\n",
    "system_prompt = \"Provide a clear and sound answer to the question. Use the source of information, if given, to answer.\"\n",
    "sampling_params = {\"temperature\": 0.2}\n",
    "\n",
    "common_params = {\n",
    "    \"dataset\": dataset[\"name\"],\n",
    "    \"metrics\": [\"judge_precision\", \"output_length\"],\n",
    "    \"model\": {\"sampling_params\" : sampling_params, \"system_prompt\": system_prompt},\n",
    "    \"judge_model\": {\n",
    "        \"name\": \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\", \"base_url\": ALBERT_API_URL, \"api_key\": ALBERT_API_KEY\n",
    "    },\n",
    "    \"sample\": sample,\n",
    "}\n",
    "\n",
    "grid_params = {\n",
    "    \"model\": [\n",
    "        {\"name\": \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\", \"base_url\": ALBERT_API_URL, \"api_key\": ALBERT_API_KEY}\n",
    "    ],\n",
    "}\n",
    "\n",
    "expset = {\n",
    "    \"name\": expset_name,\n",
    "    \"readme\": expset_readme,\n",
    "    \"cv\": {\"common_params\": common_params, \"grid_params\": grid_params, \"repeat\": 1},\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{EVALAP_API_URL}/experiment_set\",\n",
    "    headers={\"Authorization\": f\"Bearer {EVALAP_API_KEY}\", \"Content-Encoding\": \"gzip\"},\n",
    "    json=expset,\n",
    ")\n",
    "resp = response.json()\n",
    "if \"id\" in resp:\n",
    "    expset_id = resp[\"id\"]\n",
    "    print(f'Created expset: {resp[\"name\"]} ({resp[\"id\"]})')\n",
    "else:\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7c5d819c-d820-4584-ad9d-c9ec04a2d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the evalap repo into the workspace\n",
    "# @FUTURE: !pip install evalap\n",
    "sys.path.append(\"../\")\n",
    "from evalap.clients.llm import LlmClient, split_think_answer\n",
    "from evalap.rag.search import SearchEngineClient\n",
    "\n",
    "\n",
    "rag_prompt = Template(\"\"\"Use the following sources of information as a source of truth if they address the question:\n",
    "\n",
    "<SOURCE>\n",
    "{% for chunk in chunks %}\n",
    "{{chunk.text}}\n",
    "\n",
    "---\n",
    "\n",
    "{% endfor %}\n",
    "</SOURCE>\n",
    "\n",
    "QUESTION: \n",
    "{{query}}\n",
    "\"\"\")\n",
    "\n",
    "# Augment a prompt with collection search\n",
    "def do_rag(query, collection_name=None, limit=5, search_method=\"hybrid\", model_embedding=None):\n",
    "    # Search relevant chunks\n",
    "    se_client = SearchEngineClient()\n",
    "    hits = se_client.search(collection_name, query, limit=limit, method=search_method, model_embedding=model_embedding)\n",
    "    # Render prompt\n",
    "    return rag_prompt.render(query=query, chunks=hits, limit=limit)\n",
    "\n",
    "# The LLM core generation\n",
    "def generate_with_rag(prompt, model=None, system_prompt=system_prompt, with_rag=True, sampling_params=None, **rag_params):\n",
    "    if not sampling_params:\n",
    "        sampling_params = {}\n",
    "        \n",
    "    if with_rag:\n",
    "        prompt = do_rag(prompt, **rag_params)\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    if system_prompt:\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
    "        \n",
    "    aiclient = LlmClient()\n",
    "    result = aiclient.generate(model=model, messages=messages, **sampling_params)\n",
    "    observation = result.choices[0].message.content\n",
    "    think, answer = split_think_answer(observation)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31b924c1-0f80-4f89-a266-07bafe389364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following sources of information as a source of truth if they address the question:\n",
      "\n",
      "<SOURCE>\n",
      "\n",
      "1\n",
      "\n",
      "Source: CNS PHARMACEUTICALS, INC., 8-K, 3/26/2020\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "Source: CNS PHARMACEUTICALS, INC., 8-K, 3/26/2020\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "Source: CNS PHARMACEUTICALS, INC., 8-K, 3/26/2020\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "</SOURCE>\n",
      "\n",
      "QUESTION: \n",
      "CNI\n"
     ]
    }
   ],
   "source": [
    "print(do_rag(\"CNI\", collection_name=\"legalbenchrag_v1\", model_embedding=\"BAAI/bge-m3\", limit=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c44dfa6c-61c3-4bda-bd42-a17e9611b3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM API error: Internal Server Error\n",
      "\n",
      "Error: 500 Server Error: Internal Server Error for url: https://albert.api.etalab.gouv.fr/v1/embeddings, retrying in 5 seconds...\n",
      "LLM Generation Error: <html>\n",
      "<head><title>504 Gateway Time-out</title></head>\n",
      "<body>\n",
      "<center><h1>504 Gateway Time-out</h1></center>\n",
      "<hr><center>nginx/1.27.4</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "Error: 504 Server Error: Gateway Time-out for url: https://albert.api.etalab.gouv.fr/v1/chat/completions, retrying in 5 seconds...\n",
      "LLM Generation Error: <html>\n",
      "<head><title>504 Gateway Time-out</title></head>\n",
      "<body>\n",
      "<center><h1>504 Gateway Time-out</h1></center>\n",
      "<hr><center>nginx/1.27.4</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "Error: 504 Server Error: Gateway Time-out for url: https://albert.api.etalab.gouv.fr/v1/chat/completions, retrying in 5 seconds...\n"
     ]
    }
   ],
   "source": [
    "# Async computing -- RAG generation\n",
    "# --\n",
    "from functools import partial\n",
    "\n",
    "# The models to runs\n",
    "models = [\n",
    "   {\n",
    "     \"aliased_name\": \"model_hybrid_7_bgem3\",\n",
    "     \"model\": \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\", \n",
    "     \"collection_name\": \"legalbenchrag_v1\",\n",
    "     \"model_embedding\": \"BAAI/bge-m3\",\n",
    "     \"search_method\": \"hybrid\",\n",
    "     \"limit\": 7,\n",
    "     \"system_prompt\": system_prompt,\n",
    "     \"sampling_params\": sampling_params,\n",
    "    },\n",
    "    {\n",
    "     \"aliased_name\": \"model_semantic_7_bgem3\",\n",
    "     \"model\": \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\", \n",
    "     \"collection_name\": \"legalbenchrag_v1\",\n",
    "     \"model_embedding\": \"BAAI/bge-m3\",\n",
    "     \"search_method\": \"semantic\",\n",
    "     \"limit\": 7,\n",
    "     \"system_prompt\": system_prompt,\n",
    "     \"sampling_params\": sampling_params,\n",
    "    },\n",
    "    {\n",
    "     \"aliased_name\": \"model_lexical_7_bgem3\",\n",
    "     \"model\": \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\", \n",
    "     \"collection_name\": \"legalbenchrag_v1\",\n",
    "     \"model_embedding\": \"BAAI/bge-m3\",\n",
    "     \"search_method\": \"lexical\",\n",
    "     \"limit\": 7,\n",
    "     \"system_prompt\": system_prompt,\n",
    "     \"sampling_params\": sampling_params,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Loop over the model to try\n",
    "model_answers = []\n",
    "for model in models:\n",
    "    # Create a list of model arguments (same model repeated for each prompt)\n",
    "    prompts = dataset_df.iloc[sample]['query'].tolist()\n",
    "    params_to_partial = {\n",
    "        k: model[k]\n",
    "        for k in [\"model\", \"collection_name\", \"model_embedding\", \"search_method\", \"limit\", \"system_prompt\", \"sampling_params\"] \n",
    "        if model.get(k)\n",
    "    }\n",
    "    generate_with_rag_partial = partial(generate_with_rag, **params_to_partial)\n",
    "\n",
    "    # Async over the prompts\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        # Map generate over pairs of (model, prompt)\n",
    "        results = list(executor.map(generate_with_rag_partial, prompts))\n",
    "\n",
    "    model_answers.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6c0af8e8-cc10-47da-9aaf-8a102156b432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for answers in model_answers:\n",
    "    print(len([x for x in answers if x.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d3744c5f-cae7-427a-a765-a630e6b0f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch expset: LegalBenchRAG Evaluation v3 (50)\n"
     ]
    }
   ],
   "source": [
    "# Adding RAG model to the experiment set\n",
    "# --\n",
    "common_params = {\n",
    "    \"dataset\": dataset[\"name\"],\n",
    "    \"metrics\": [\"judge_precision\", \"output_length\"],\n",
    "    \"model\": {\"sampling_params\" : sampling_params, \"system_prompt\": system_prompt},\n",
    "    \"judge_model\": {\n",
    "        \"name\": \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\", \"base_url\": ALBERT_API_URL, \"api_key\": ALBERT_API_KEY\n",
    "    },\n",
    "    \"sample\": sample,\n",
    "}\n",
    "\n",
    "grid_params = {\n",
    "    \"model\": [\n",
    "        {\n",
    "            \"aliased_name\": model[\"aliased_name\"],\n",
    "            \"name\": model[\"model\"],\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"sampling_params\": sampling_params,\n",
    "            \"output\": model_answers[i],\n",
    "        }\n",
    "        for i, model in enumerate(models)    \n",
    "    ],\n",
    "}\n",
    "\n",
    "expset = {\n",
    "    \"cv\": {\"common_params\": common_params, \"grid_params\": grid_params, \"repeat\": 1},\n",
    "}\n",
    "\n",
    "response = requests.patch(\n",
    "    f\"{EVALAP_API_URL}/experiment_set/{expset_id}\",\n",
    "    headers={\"Authorization\": f\"Bearer {EVALAP_API_KEY}\", \"Content-Encoding\": \"gzip\"},\n",
    "    json=expset,\n",
    ")\n",
    "resp = response.json()\n",
    "if \"id\" in resp:\n",
    "    expset_id = resp[\"id\"]\n",
    "    print(f'Patch expset: {resp[\"name\"]} ({resp[\"id\"]})')\n",
    "else:\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7768cf-97f5-4242-9319-863af47dd7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
