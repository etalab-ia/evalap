{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64b1ae0-5f1a-4d0a-80cb-aac515cef44a",
   "metadata": {},
   "source": [
    "# Ad-hoc RAG\n",
    "\n",
    "Evaluate results from an ad-hoc RAG similar than the one behind franceservices.etalab.gouv.fr using evalap and ModelRaw schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040307b-da60-4144-93ec-827967cd4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from io import StringIO\n",
    "import concurrent.futures\n",
    "\n",
    "import dotenv\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from jinja2 import Template\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "sys.path.append(\"..\")\n",
    "from evalap.utils import log_and_raise_for_status\n",
    "\n",
    "EVALAP_API_URL = \"http://localhost:8000/v1\"\n",
    "#EVALAP_API_URL = \"https://evalap.etalab.gouv.fr/v1\"\n",
    "EVALAP_API_KEY = os.getenv(\"EVALAP_API_KEY\") \n",
    "ALBERT_API_URL = \"https://albert.api.etalab.gouv.fr/v1\"\n",
    "ALBERT_API_KEY = os.getenv(\"ALBERT_API_KEY\")\n",
    "OPENAI_URL = \"https://api.openai.com/v1\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "headers = {\"Authorization\": f\"Bearer {EVALAP_API_KEY}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4307c-a7b3-40f7-bc4e-e025c825eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "dataset_name = \"MFS_questions_v01\"\n",
    "response = requests.get(\n",
    "    f\"{EVALAP_API_URL}/dataset?name={dataset_name}&with_df=true\",\n",
    "    headers={\"Authorization\": f\"Bearer {EVALAP_API_KEY}\"},\n",
    ")\n",
    "response.raise_for_status()\n",
    "dataset = response.json()\n",
    "dataset_df =  pd.read_json(StringIO(dataset[\"df\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec5d7f-c129-46ac-a341-b0653a5f541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../mcp-servers/data-gouv-fr/\")\n",
    "from clients.search import SearchEngineClient\n",
    "from clients.llm import LlmClient, split_think_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c1acf-753f-4b63-b44f-17be7f7ca933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = {\"temperature\": 0.2}\n",
    "collection_name = \"chunks-v6\"\n",
    "model_embedding = \"BAAI/bge-m3\"\n",
    "limit = 10\n",
    "\n",
    "system_prompt = \"Tu es un agent de l'état Français qui répond en langue française aux questions des usagers des services publiques et citoyens de manière précise, concrète et concise.\"\n",
    "rag_prompt = Template(\"\"\"Ecris un texte référencé en réponse à cette question : {{query}}\n",
    "\n",
    "Les références doivent être citées de cette manière (échape les guillements avec \\\\\", s'il y en a, dans les attributs de <ref>) : texte rédigé <ref title=\"[titre de la source]\" text=\"[passage pertinent dans la référence]\">[URL de la source]</ref>\n",
    "\n",
    "Si les références ne permettent pas de répondre, spécifie juste qu'il n'y a pas de réponse.\n",
    "\n",
    "Les {{limit}} références disponibles :\n",
    "{% for chunk in chunks %}\n",
    "url: {{chunk.url}}\n",
    "title: {{chunk.title}} {% if chunk.context %}({{chunk.context}}){% endif %}\n",
    "text: {{chunk.text}} {% if not loop.last %}{{\"\\n\"}}{% endif %}\n",
    "{% endfor %}\n",
    "\"\"\")\n",
    "\n",
    "# Augment a prompt with collection search\n",
    "def do_rag(query, limit=limit):\n",
    "    # Search relevant chunks\n",
    "    se_config = dict(\n",
    "        es_url=os.getenv(\"ELASTICSEARCH_URL\"),\n",
    "        es_creds=(\"elastic\", os.getenv(\"ELASTICSEARCH_PASSWORD\")),\n",
    "        model_embedding=model_embedding,\n",
    "    )\n",
    "    se_client = SearchEngineClient(**se_config)\n",
    "    hits = se_client.search(collection_name, query, limit=limit)\n",
    "\n",
    "    # Render prompt\n",
    "    return rag_prompt.render(query=query, chunks=hits, limit=limit)\n",
    "\n",
    "# The LLM core generation\n",
    "def generate(model, prompt, use_system_prompt=True):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    if use_system_prompt:\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
    "        \n",
    "    aiclient = LlmClient()\n",
    "    result = aiclient.generate(model=model, messages=messages, **sampling_params)\n",
    "    observation = result.choices[0].message.content\n",
    "    think, answer = split_think_answer(observation)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634e72d-78c3-40bb-a410-21596e20a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(do_rag(\"CNI\", limit=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501211f-c850-428e-bdb9-2d51eb5cb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async computing\n",
    "# --\n",
    "\n",
    "# The models to runs\n",
    "models = [\"AgentPublic/llama3-instruct-guillaumetell\", \"meta-llama/Llama-3.1-8B-Instruct\", \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"]\n",
    "\n",
    "# the input prompts to answer\n",
    "prompts = []\n",
    "for i, row in dataset_df.iterrows():\n",
    "    prompts.append(do_rag(row[\"query\"]))\n",
    "\n",
    "# Loop over the model to try\n",
    "model_raws = []\n",
    "for model in models:\n",
    "    # Async over the prompts\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        # Create a list of model arguments (same model repeated for each prompt)\n",
    "        model_args = [model] * len(prompts)\n",
    "\n",
    "        # Map generate over pairs of (model, prompt)\n",
    "        results = list(executor.map(generate, model_args, prompts))\n",
    "\n",
    "    model_raws.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379a9f9-ab86-40d3-8042-59f3a7f1a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_name = \"gpt-4.1\"\n",
    "judge_api_url = \"https://api.openai.com/v1\",\n",
    "judge_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdfa88-95ef-4adb-ad96-775628a42ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the expset\n",
    "# --\n",
    "expset_name = \"MFS ad-hoc RAG\"\n",
    "expset_readme = \"MFS ad-hoc RAG (similar parametriation than expset 50)\"\n",
    "common_params = {\n",
    "    \"dataset\": dataset[\"name\"],\n",
    "    \"metrics\": [\"judge_precision\", \"output_length\"],\n",
    "    \"judge_model\": {\n",
    "        \"name\": judge_name,\n",
    "        \"base_url\": judge_api_url,\n",
    "        \"api_key\": judge_api_key,\n",
    "},\n",
    "}\n",
    "\n",
    "grid_params = {\n",
    "    \"model\": [\n",
    "        {\n",
    "            \"aliased_name\": models[i].split(\"/\")[-1] + \"-adhoc-rag\",\n",
    "            \"name\": models[i],\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"sampling_params\": sampling_params,\n",
    "            \"output\": outputs,\n",
    "        }\n",
    "        for i, outputs in enumerate(model_raws)\n",
    "    ],\n",
    "}\n",
    "\n",
    "expset = {\n",
    "    \"name\": expset_name,\n",
    "    \"readme\": expset_readme,\n",
    "    \"cv\": {\"common_params\": common_params, \"grid_params\": grid_params, \"repeat\": 1},\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{EVALAP_API_URL}/experiment_set\",\n",
    "    headers={\"Authorization\": f\"Bearer {EVALAP_API_KEY}\", \"Content-Encoding\": \"gzip\"},\n",
    "    json=expset,\n",
    ")\n",
    "resp = response.json()\n",
    "if \"id\" in resp:\n",
    "    expset_id = resp[\"id\"]\n",
    "    print(f'Created expset: {resp[\"name\"]} ({resp[\"id\"]})')\n",
    "else:\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c9e5e-5fa3-4260-a588-50c1286e5249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
