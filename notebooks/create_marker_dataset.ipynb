{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd82f64-6a10-4aeb-af51-69046db4ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, json, re, io\n",
    "import base64\n",
    "import dotenv\n",
    "import requests\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image \n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "sys.path.append(\"..\")\n",
    "from evalap.utils import log_and_raise_for_status\n",
    "\n",
    "EVALAP_API_URL = \"http://localhost:8000/v1\"\n",
    "#EVALAP_API_URL = \"http://localhost:8000/v1\"\n",
    "EVALAP_API_KEY = os.getenv(\"EVALAP_API_KEY\") \n",
    "ALBERT_API_URL = \"https://albert.api.etalab.gouv.fr/v1\"\n",
    "ALBERT_API_KEY = os.getenv(\"ALBERT_API_KEY\")\n",
    "\n",
    "evalap_headers = {\"Authorization\": f\"Bearer {EVALAP_API_KEY}\"}\n",
    "albert_headers = {\"Authorization\": f\"Bearer {ALBERT_API_KEY}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b3db3-aacd-4c99-9587-18c2d99422ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"datalab-to/marker_benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa7696-c82c-4a43-8bca-497b783825c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057b180-bca4-45ac-a55b-dd0dc6d88dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What a row contains \n",
    "\n",
    "for key, value in ds[\"train\"][1261].items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c6a30-2aec-4151-be8d-d9930ed16bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the first block content (gt_blocks)\n",
    "\n",
    "jsb = json.loads(ds[\"train\"][0][\"gt_blocks\"])\n",
    "\n",
    "for block in jsb:\n",
    "    print(list(block))\n",
    "    print(block)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f08cd-668d-4e14-8e12-9adaa688d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_row(row):\n",
    "    \"\"\"\n",
    "    Display a dataset row nicely in a Jupyter notebook.\n",
    "    \n",
    "    Args:\n",
    "    - row: dictionary containing elements like 'gt_blocks', 'img', etc.\n",
    "    \"\"\"\n",
    "    for key, value in row.items():\n",
    "        if isinstance(value, Image.Image):  # Use Image.Image to check for PIL images\n",
    "            print(f\"{key}: Image\")\n",
    "            display(value)\n",
    "        elif key == \"gt_blocks\":\n",
    "            blocks = json.loads(value)\n",
    "            print(f'{len(blocks)} blocks. Block types: {[x.get(\"block_type\") for x in blocks]}')\n",
    "            #for block in blocks:\n",
    "            #    print(block[\"html\"])\n",
    "        elif isinstance(value, str):\n",
    "            print(f\"{key}: {value}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"{key}: {value}\")\n",
    "        elif isinstance(value, int):\n",
    "            print(f\"{key}: {value}\")\n",
    "        elif isinstance(value, bytes):\n",
    "            print(f\"{key}: {len(value)} bytes\")\n",
    "        else:\n",
    "            print(f\"{key}: {type(value)} (unable to display)\")\n",
    "\n",
    "def image_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert a PIL image to a base64-encoded PNG bytes string.\n",
    "    \"\"\"\n",
    "    with io.BytesIO() as buffer:\n",
    "        pil_image.save(buffer, format=\"PNG\")\n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def extract_code(text: str):\n",
    "    \"\"\"Return the last code block found\"\"\"\n",
    "    # Find all blocks of code wrapped in triple backticks\n",
    "    matches = re.findall(r\"```(?:\\w+)?\\n(.*?)```\", text, re.DOTALL)\n",
    "    if matches:\n",
    "        # Return the last code block found\n",
    "        code = matches[-1]\n",
    "        # Remove any leading or trailing whitespace\n",
    "        code = code.strip()\n",
    "        return code\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def pandoc(content, input_format=\"html\", output_format=\"markdown\"):\n",
    "    \"\"\"\n",
    "    Convert HTML to Markdown using Pandoc\n",
    "\n",
    "    Parameters:\n",
    "    - html_content: The HTML string to convert\n",
    "    - output_format: The specific Markdown flavor (e.g., \"markdown\", \"markdown_strict\", \"gfm\" for GitHub-flavored Markdown)\n",
    "\n",
    "    Returns:\n",
    "    - Markdown text\n",
    "    \"\"\"\n",
    "    # Create a process that runs pandoc\n",
    "    process = subprocess.Popen(\n",
    "        ['pandoc', '-f', input_format, '-t', output_format],\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    # Send the HTML content to pandoc and get the output\n",
    "    new_content, error = process.communicate(input=content)\n",
    "    if process.returncode != 0:\n",
    "        raise Exception(f\"Pandoc conversion failed: {error}\")\n",
    "\n",
    "    return new_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdeb5f-c65e-4dd0-b33d-34f35d2dd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataset_row(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c76c88-da7e-4841-973b-585d1240a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are tasked with generating a JSON representation from the analysis (OCR) of a given image. \n",
    "Your goal is to create a JSON object that has the content of the image extracted in a structured format. \n",
    "\n",
    "The JSON should be structured to represent the content of the image in a way that corresponds to standard markdown primitives. Here's how to approach this task:\n",
    "\n",
    "The JSON should contain a list of blocks, where each block represents a distinct element in the image, such as headers, paragraphs, or tables.\n",
    "Here is a an exemple of the json schema wanted: \n",
    "\n",
    "Schema:\n",
    "```json\n",
    "[\n",
    " {\n",
    "   \"type\": \"string (e.g  Text, Table, Code, SectionHeader, Figure, Equation, Handwriting, PageFooter, PageHeader, Picture, TableOfContents etc)\",\n",
    "   \"text\": \"string (mardown formated text)\"\n",
    " },\n",
    " ...\n",
    "]\n",
    "```\n",
    "\n",
    "Example:\n",
    "```json\n",
    "[\n",
    " {\n",
    "    \"type\": \"Header\", \"text\": \"## I am a level 2 header\"\n",
    " },\n",
    " {\n",
    "   \"type\": \"Paragraph\", \"text\": \"I am a **paragraph**\"\n",
    " }\n",
    "]\n",
    "````\n",
    "\n",
    "Follow these guidelines when creating the JSON:\n",
    "\n",
    "1. The main structure should be a list of blocks. Each block are object containing a `type` and a `text field`.\n",
    "2. Each block is an object containing a `type` and a `text field`. They should correspond to a standard markdown primitive (e.g., Header, Paragraph, Table).\n",
    "3. Identify headers based on font size, weight, or positioning. These should be represented as \"Header\" blocks.\n",
    "4. Group continuous lines of text into \"Paragraph\" blocks.\n",
    "5. Identify tabular data and represent it as \"Table\" blocks. Only create table blocks for actual tabular data, not for text formatting.\n",
    "6. Do not create separate blocks for inline formatting (bold, italic) or URLs. Keep these within the relevant \"Paragraph\" block.\n",
    "7. If you encounter lists, represent them as \"List\" blocks, with nested items if applicable.\n",
    "8. For images or diagrams, use an \"Image\" block and include any available descriptive text.\n",
    "\n",
    "Remember, the goal is to create a structured representation of the image content that could be easily converted to markdown or used for further processing. Focus on the main structural elements and avoid over-complicating the JSON with minor formatting details.\n",
    "\n",
    "Do not explain your answer. Just answer with the JSON result directly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4ca4f-81fb-4c4c-81a5-785355678b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albert OCR request\n",
    "# @DEBUG: do not work yet\n",
    "\n",
    "url = \"https://albert.api.etalab.gouv.fr/v1/ocr-beta\"\n",
    "model = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n",
    "payload = {\n",
    "    \"model\": model,\n",
    "    \"prompt\": system_prompt,\n",
    "    #\"file\": \"data:image/png;base64,\" + image_to_base64(ds[\"train\"][0][\"img\"]),\n",
    "}\n",
    "\n",
    "ds[\"train\"][0][\"img\"].save('tmp-img-marker-0.pdf', \"PDF\", resolution=300)\n",
    "files = {\n",
    "    'file': open(\"tmp-img-marker-0.pdf\", \"rb\")\n",
    "}\n",
    "\n",
    "# Send the request\n",
    "response = requests.post(url, headers=albert_headers, data=payload, files=files)\n",
    "log_and_raise_for_status(response, \"LLM API error\")\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0b3cc-30fc-46d1-af72-f3af968169db",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://albert.api.etalab.gouv.fr/v1/chat/completions\"\n",
    "model = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n",
    "messages = [\n",
    "    #{\n",
    "    #    \"role\": \"system\",\n",
    "    #    \"content\": \"system_prompt\n",
    "    #},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"data:image/png;base64,\" + image_to_base64(ds[\"train\"][0][\"img\"]),\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"model\": model,\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.2\n",
    "}\n",
    "\n",
    "# Send the request\n",
    "response = requests.post(url, headers=albert_headers, json=payload)\n",
    "log_and_raise_for_status(response, \"LLM API error\")\n",
    "result = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d924c49-3c7c-4574-812e-dd8fb1d2146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(extract_code(result[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d90dd6-5d08-4a6a-8af0-73e830d31e04",
   "metadata": {},
   "source": [
    "### Push dataset on EVALAP\n",
    "\n",
    "1. add `json_output_true` column in the dataset\n",
    "2. create the dataset (empty)\n",
    "3. stream the parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20339bef-fc6f-43ac-a710-991540a0ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the `json_output_true`\n",
    "\n",
    "def create_json_output_true(row):\n",
    "    blocks = json.loads(row[\"gt_blocks\"])\n",
    "    v = []\n",
    "    texts = []\n",
    "    for block in blocks:\n",
    "        text = pandoc(block[\"html\"]).strip()\n",
    "        v.append({\n",
    "            'bbox': block[\"bbox\"], \n",
    "            'polygon': block[\"polygon\"], \n",
    "            'type': block[\"block_type\"],\n",
    "            'text': text,\n",
    "        })\n",
    "        texts.append(text)\n",
    "    markdown = \"\\n\\n\".join(texts)\n",
    "    return {\"json_output_true\": v, \"markdown_true\": markdown}\n",
    "\n",
    "ds[\"train\"] = ds[\"train\"].map(create_json_output_true)\n",
    "ds[\"train\"] = ds[\"train\"].remove_columns([\"gt_blocks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2c106-b966-4e50-b5dd-d9ab66160a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to save the dataset as a parquet file (its around 700 Mo)\n",
    "ds[\"train\"].to_parquet(\"dataset_test.parquet\", compression=\"gzip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35608ed8-a672-49d3-bba9-5425795289d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "pf = pq.ParquetFile(\"dataset_test.parquet\")\n",
    "num_rows = pf.metadata.num_rows\n",
    "column_names = pf.schema_arrow.names\n",
    "\n",
    "print(\"num rows\", num_rows)\n",
    "print(\"column names\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362dba8-0cb3-4678-95b2-190d5305cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in pf.iter_batches(batch_size=1):\n",
    "    df = batch.to_pandas()\n",
    "    display(df.head())\n",
    "    # Open the image using Pillow\n",
    "    image = Image.open(io.BytesIO(df[\"img\"].iloc[0][\"bytes\"]))\n",
    "    print(image.format)\n",
    "    i += 1\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96570f92-3a66-4639-919b-0aee6f4a45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = {\"name\": \"OCR_marker_benchmark\", \"readme\": \"Marker benchmark. See https://github.com/VikParuchuri/marker\"\n",
    "           , \"default_metric\" : \"ocr_v1\"\n",
    "           , \"df\": \"{}\"}\n",
    "\n",
    "response = requests.post(f'{EVALAP_API_URL}/dataset', json=dataset, headers=evalap_headers)\n",
    "dataset = response.json()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af51e32-5260-415e-a2fb-54ee2c87388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stream data in chunks\n",
    "def stream_data(buffer, chunk_size=1024*1024):\n",
    "    buffer.seek(0)\n",
    "    while True:\n",
    "        chunk = buffer.read(chunk_size)\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk\n",
    "\n",
    "\n",
    "# Create an in-memory buffer\n",
    "buffer = io.BytesIO()\n",
    "\n",
    "# Write directly to parquet without converting to pandas first\n",
    "ds['train'].to_parquet(buffer, compression=\"gzip\")\n",
    "\n",
    "# Upload the data using a streaming POST request\n",
    "headers = {'Content-Type': 'application/octet-stream'} | evalap_headers\n",
    "response = requests.post(f'{EVALAP_API_URL}/dataset/{dataset[\"id\"]}/upload_parquet', data=stream_data(buffer, chunk_size=262144), headers=headers)\n",
    "\n",
    "# Check the response\n",
    "if response.ok:\n",
    "    print(\"Upload successful!\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(\"Upload failed:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434430e8-e558-4217-8095-175d4878c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch the dataset to add a dolumn map to indicate where is **output_true**\n",
    "# --\n",
    "\n",
    "# Define the data to be patched\n",
    "data = {\n",
    "    \"columns_map\": {\n",
    "        \"output_true\": \"markdown_true\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make the PATCH request\n",
    "response = requests.patch(f'{EVALAP_API_URL}/dataset/{dataset[\"id\"]}', headers=evalap_headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472601a3-eab6-4660-9c6f-398fdcc831c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
